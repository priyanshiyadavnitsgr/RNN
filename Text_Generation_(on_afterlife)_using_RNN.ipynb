{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text_Generation (on afterlife) using RNN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/priyanshiyadavnitsgr/Recurrent-Neural-Network/blob/master/Text_Generation_(on_afterlife)_using_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ivjRyku3sMSP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BmtSddNsWDS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text=open('/content/Afterlife.txt').read()\n",
        "text=text.lower()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIXDQAcR0cVc",
        "colab_type": "code",
        "outputId": "5365124b-5f9e-41cb-d2b3-219e6986a107",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "text"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ufeffthe afterlife\\nprincess diana stood at the entrance to the bar, dazzled by the flash of cameras. a few drinkers turned in her direction as she entered, and one or two waved. she paused in front of the floor light so that it shone through her diaphanous dress for a moment, then headed for the bar.\\n\\n“hi, micky.”\\n\\nmichael jackson swivelled on his bar stool and grinned a welcome.\\n\\n“well good evening,” he said, beaming, leaving a small gap before adding “your highness”.\\n\\nprincess diana blushed, dipped her head and looked up at him through artfully sculpted lashes.\\n\\n“oh, you,” she muttered playfully, but glad that he’d used the title. michael jackson had always had a thing for princess di, and diana knew it, but it would have been impossible to acknowledge the existence of any romantic interest. they occupied very different worlds. for a moment they looked into each other’s eyes, then he glanced away and the spell broke.\\n\\n“so,” he began, “how’s the mine clearing business?”\\n\\n“oh,” she replied. “you know. those poor, poor children. someone really has to do something.”\\n\\nprincess diana tried to think of a way to continue the conversation, but she’d exhausted her knowledge of the subject. she really must research landmines, she decided. perhaps she’d make a quick visit to the ladies and check out their wikipedia entry on her phone.\\n\\n“somebody always has to do something, love,” said a liverpudlian accent at her shoulder, “but most of you posh birds just rattle your jewellery.”\\n\\nprincess diana closed her eyes and slumped a little on her bar stool.\\n\\n“hi john,” she said in a weary tone.\\n\\n“you may say i’m a dreamer,” he continued. “but -” he left a pause, and princess diana turned to him with a pitying glance.\\n\\n“you’re not the only one?” she said wearily.\\n\\n“too right love,” he added. “i hope some day you’ll join us.”\\n\\n“yes, john,” said diana.\\n\\n“i read the news today -” john lennon began.\\n\\n“oh boy,” interrupted jackson. “look, john, we’re in the middle of a conversation here.”\\n\\n“okay, okay,” lennon said, backing off, his hands raised in mock surrender. “we all want to change the world. well. you know.” and he wandered off into the darkness.\\n\\n“jesus fuck,” said princess diana. “he don’t half go on with them bloody lyrics. it really does me head in.”\\n\\n“character, girl,” said michael jackson softly, swirling an ice cube in the remains of his orange juice.\\n\\n“oh, my goodness,” exclaimed princess diana, raising a hand to her mouth and blushing deeply, “i’m most terribly, terribly sorry. one must never let one’s emotions overrule one’s sense of decorum.”\\n\\n“so, your majesty,” michael jackson said, “the usual?” he signalled to humphrey bogart behind the bar, who folded his racing post and walked over.\\n\\n“pimm’s?” said bogart, reaching for a tall glass. “of all the pimm’s joints in all the bars in all the world…” he added, before ducking under the bar to search for limes and cucumber.\\n\\n“now that,” said michael jackson, “is class. see? keep it light. don’t lay it on with a trowel. you can’t beat it – beat it.”\\n\\nprincess diana looked up at him.\\n\\n“it’s all very well for you,” she said, “but i don’t have your quotes catalogue.”\\n\\n“hell, babe,” said bogart, “you got your looks. flutter those eyelashes and you got any red-blooded male eating out of your hand. you just have to whistle. you know how to whistle, don’t you?”\\n\\n“strictly speaking -” began michael jackson.\\n\\n“i know, i know,” said bogart, backing away to his perch in the corner, “and if lauren ever makes it in here i’ll be sure to give her her line back.”\\n\\nthey were interrupted by a crash by the door, as someone tripped over the spotlight, tumbled backwards and knocked over the seven-foot replica oscar. princess diana hurried over, and peered down at a short, white-haired black man in a garish shirt being helped to his feet by george best.\\n\\n“nelson mandela?” she asked.\\n\\nmandela looked around him, bewildered. “fucking hell,” he said, “what the fuck was that?”\\n\\n“it’s the paps,” said george best. “humphrey rigged them up. only cardboard, but it works.”\\n\\n“begorrah,” he added, a little uncertainly.\\n\\n“fucking hell,” said nelson mandela again, “they fucking blinded me.”\\n\\n“pir unit,” said humphrey bogart, lifting the statue back up. “led spotlights in the cameras, set to a one-fiftieth burst flash.” he examined the damaged spotlight. “i got an hnd in electrical engineering,” he added, scooping out the shards of broken bulb with a beer mat.\\n\\nprincess diana took nelson mandela’s arm.\\n\\n“first time?” she said, before adding, “yes, of course, it must be. welcome.”\\n\\n“sorry,” said nelson mandela, settling onto a bar stool. “for the language. damn flashes. took me by surprise.”\\n\\n“you get used to them,” said michael jackson. “annoying, but we’d miss them.”\\n\\nhumphrey bogart reached behind the bar, drew out a bottle of vin de constance and poured a generous measure.\\n\\n“been saving this for years,” he said. “mandela’s favourite tipple.”\\n\\nnelson mandela took an exploratory sip.\\n\\n“jesus,” he said, “that’s disgusting. do i have to?”\\n\\n“listen, man,” said michael jackson, “who we are is all we’ve got. and that goes for your language as well. i’m guessing you didn’t get a lot of voice work?”\\n\\nnelson mandela shook his head.\\n\\n“mainly film,” he said, “in the background. the camera pans over a line-up of world leaders. they put me next to margaret thatcher.”\\n\\n“yes,” said michael jackson, “she’s a regular.”\\n\\nmandela looked around the room, spotting the celebrities sitting at low tables. bobby charlton shared a table with lou reed and david frost, whitney houston was deep in conversation with larry hagman.\\n\\n“all dead?” he asked.\\n\\n“of course,” said michael jackson. “it’s a lookalike’s curse. once our principals die, our work stops. marilyn gets a few corporates. the rest of us – nothing. that’s why humphrey set up this bar.”\\n\\nhe knocked back the remains of his orange juice.\\n\\n“welcome to the afterlife.”'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSnpDrMe0hDP",
        "colab_type": "text"
      },
      "source": [
        "### We will be using word by word mapping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEwcPttF0dxz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "characters=sorted(list(set(text)))\n",
        "\n",
        "n_to_char={n: char for n, char in enumerate(characters)}\n",
        "char_to_n={char: n for n, char in enumerate(characters)}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xGnaQHD04x-",
        "colab_type": "code",
        "outputId": "29398cb4-1e20-4737-80c6-2df711067f92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 692
        }
      },
      "source": [
        "n_to_char"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: '\\n',\n",
              " 1: ' ',\n",
              " 2: ',',\n",
              " 3: '-',\n",
              " 4: '.',\n",
              " 5: '?',\n",
              " 6: 'a',\n",
              " 7: 'b',\n",
              " 8: 'c',\n",
              " 9: 'd',\n",
              " 10: 'e',\n",
              " 11: 'f',\n",
              " 12: 'g',\n",
              " 13: 'h',\n",
              " 14: 'i',\n",
              " 15: 'j',\n",
              " 16: 'k',\n",
              " 17: 'l',\n",
              " 18: 'm',\n",
              " 19: 'n',\n",
              " 20: 'o',\n",
              " 21: 'p',\n",
              " 22: 'q',\n",
              " 23: 'r',\n",
              " 24: 's',\n",
              " 25: 't',\n",
              " 26: 'u',\n",
              " 27: 'v',\n",
              " 28: 'w',\n",
              " 29: 'x',\n",
              " 30: 'y',\n",
              " 31: 'z',\n",
              " 32: '–',\n",
              " 33: '’',\n",
              " 34: '“',\n",
              " 35: '”',\n",
              " 36: '…',\n",
              " 37: '\\ufeff'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GrvUoEog2bFH",
        "colab_type": "code",
        "outputId": "7e2bd726-e92d-4283-95ff-0bd405f157a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 692
        }
      },
      "source": [
        "char_to_n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'\\n': 0,\n",
              " ' ': 1,\n",
              " ',': 2,\n",
              " '-': 3,\n",
              " '.': 4,\n",
              " '?': 5,\n",
              " 'a': 6,\n",
              " 'b': 7,\n",
              " 'c': 8,\n",
              " 'd': 9,\n",
              " 'e': 10,\n",
              " 'f': 11,\n",
              " 'g': 12,\n",
              " 'h': 13,\n",
              " 'i': 14,\n",
              " 'j': 15,\n",
              " 'k': 16,\n",
              " 'l': 17,\n",
              " 'm': 18,\n",
              " 'n': 19,\n",
              " 'o': 20,\n",
              " 'p': 21,\n",
              " 'q': 22,\n",
              " 'r': 23,\n",
              " 's': 24,\n",
              " 't': 25,\n",
              " 'u': 26,\n",
              " 'v': 27,\n",
              " 'w': 28,\n",
              " 'x': 29,\n",
              " 'y': 30,\n",
              " 'z': 31,\n",
              " '–': 32,\n",
              " '’': 33,\n",
              " '“': 34,\n",
              " '”': 35,\n",
              " '…': 36,\n",
              " '\\ufeff': 37}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3bhdnaA589E",
        "colab_type": "text"
      },
      "source": [
        "#### Our aim here is to designate each character an interger value. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9PR9U-X2qdA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x=[]\n",
        "y=[]\n",
        "\n",
        "length=len(text)\n",
        "seq_length=100\n",
        "for i in range(100, length, 1):\n",
        "  sequence=text[i-100:i]\n",
        "  label=text[i]\n",
        "  x.append([char_to_n[char] for char in sequence])\n",
        "  y.append(char_to_n[label])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IkMUGdYz7j3x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_modified=np.reshape(x, (len(x), seq_length,1))\n",
        "x_modified = x_modified / float(len(characters))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GnmBjhd7uxS",
        "colab_type": "code",
        "outputId": "46b72031-c83b-4877-8d13-783583481166",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 888
        }
      },
      "source": [
        "x_modified"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0.97368421],\n",
              "        [0.65789474],\n",
              "        [0.34210526],\n",
              "        ...,\n",
              "        [0.15789474],\n",
              "        [0.02631579],\n",
              "        [0.28947368]],\n",
              "\n",
              "       [[0.65789474],\n",
              "        [0.34210526],\n",
              "        [0.26315789],\n",
              "        ...,\n",
              "        [0.02631579],\n",
              "        [0.28947368],\n",
              "        [0.26315789]],\n",
              "\n",
              "       [[0.34210526],\n",
              "        [0.26315789],\n",
              "        [0.02631579],\n",
              "        ...,\n",
              "        [0.28947368],\n",
              "        [0.26315789],\n",
              "        [0.73684211]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[0.47368421],\n",
              "        [0.55263158],\n",
              "        [0.34210526],\n",
              "        ...,\n",
              "        [0.44736842],\n",
              "        [0.36842105],\n",
              "        [0.28947368]],\n",
              "\n",
              "       [[0.55263158],\n",
              "        [0.34210526],\n",
              "        [0.60526316],\n",
              "        ...,\n",
              "        [0.36842105],\n",
              "        [0.28947368],\n",
              "        [0.26315789]],\n",
              "\n",
              "       [[0.34210526],\n",
              "        [0.60526316],\n",
              "        [0.26315789],\n",
              "        ...,\n",
              "        [0.28947368],\n",
              "        [0.26315789],\n",
              "        [0.10526316]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TB6ueGRxA81r",
        "colab_type": "code",
        "outputId": "2339cd03-5aef-47cf-84fa-ada630c4a55e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "x_modified.shape"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5804, 100, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5IEfTUdT7skm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.utils import np_utils\n",
        "y_modified=np_utils.to_categorical(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFOycyPl9xs6",
        "colab_type": "code",
        "outputId": "603165ed-36a1-4819-d908-b36f0026f573",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "y_modified"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 1., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 1., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3i9AbRVkBnF_",
        "colab_type": "code",
        "outputId": "303b0bf0-2201-4f09-e65d-af31ef6e4136",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "y_modified.shape"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5804, 37)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqywH7IZ-5at",
        "colab_type": "text"
      },
      "source": [
        "### Modelling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rW2UBEeD-2kX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import LSTM, Dropout, Dense\n",
        "from keras.models import Sequential\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYhuawjxB4ws",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(700, input_shape=(x_modified.shape[1], x_modified.shape[2]), return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(700, return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(700))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(y_modified.shape[1], activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQCBBoaaCqw0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jS8p5P7UDPE_",
        "colab_type": "code",
        "outputId": "da3703c4-8fb6-4230-e9af-c6eb04301c45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(x_modified, y_modified, epochs=100, batch_size=50)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "5804/5804 [==============================] - 120s 21ms/step - loss: 3.2112\n",
            "Epoch 2/100\n",
            "5804/5804 [==============================] - 118s 20ms/step - loss: 3.1217\n",
            "Epoch 3/100\n",
            "5804/5804 [==============================] - 118s 20ms/step - loss: 3.1119\n",
            "Epoch 4/100\n",
            "5804/5804 [==============================] - 117s 20ms/step - loss: 3.1435\n",
            "Epoch 5/100\n",
            "5804/5804 [==============================] - 117s 20ms/step - loss: 3.0592\n",
            "Epoch 6/100\n",
            "5804/5804 [==============================] - 117s 20ms/step - loss: 3.1012\n",
            "Epoch 7/100\n",
            "5804/5804 [==============================] - 117s 20ms/step - loss: 3.0080\n",
            "Epoch 8/100\n",
            "5804/5804 [==============================] - 118s 20ms/step - loss: 2.9370\n",
            "Epoch 9/100\n",
            "5804/5804 [==============================] - 117s 20ms/step - loss: 2.8669\n",
            "Epoch 10/100\n",
            "5804/5804 [==============================] - 117s 20ms/step - loss: 2.8136\n",
            "Epoch 11/100\n",
            "5804/5804 [==============================] - 118s 20ms/step - loss: 2.7534\n",
            "Epoch 12/100\n",
            "5804/5804 [==============================] - 117s 20ms/step - loss: 2.6913\n",
            "Epoch 13/100\n",
            "5804/5804 [==============================] - 117s 20ms/step - loss: 2.6438\n",
            "Epoch 14/100\n",
            "5804/5804 [==============================] - 118s 20ms/step - loss: 2.6246\n",
            "Epoch 15/100\n",
            "5804/5804 [==============================] - 117s 20ms/step - loss: 2.7751\n",
            "Epoch 16/100\n",
            "5804/5804 [==============================] - 117s 20ms/step - loss: 2.5143\n",
            "Epoch 17/100\n",
            "5804/5804 [==============================] - 117s 20ms/step - loss: 2.4209\n",
            "Epoch 18/100\n",
            "5804/5804 [==============================] - 117s 20ms/step - loss: 2.3551\n",
            "Epoch 19/100\n",
            "5804/5804 [==============================] - 118s 20ms/step - loss: 2.2830\n",
            "Epoch 20/100\n",
            "5804/5804 [==============================] - 117s 20ms/step - loss: 2.1985\n",
            "Epoch 21/100\n",
            "5804/5804 [==============================] - 117s 20ms/step - loss: 2.1090\n",
            "Epoch 22/100\n",
            "5804/5804 [==============================] - 118s 20ms/step - loss: 2.0033\n",
            "Epoch 23/100\n",
            "5804/5804 [==============================] - 117s 20ms/step - loss: 1.9049\n",
            "Epoch 24/100\n",
            "5804/5804 [==============================] - 117s 20ms/step - loss: 1.7650\n",
            "Epoch 25/100\n",
            "5804/5804 [==============================] - 117s 20ms/step - loss: 1.6602\n",
            "Epoch 26/100\n",
            "5804/5804 [==============================] - 117s 20ms/step - loss: 1.5130\n",
            "Epoch 27/100\n",
            "5804/5804 [==============================] - 117s 20ms/step - loss: 1.3390\n",
            "Epoch 28/100\n",
            "5804/5804 [==============================] - 117s 20ms/step - loss: 1.1529\n",
            "Epoch 29/100\n",
            "5804/5804 [==============================] - 117s 20ms/step - loss: 0.9842\n",
            "Epoch 30/100\n",
            "5804/5804 [==============================] - 117s 20ms/step - loss: 0.8087\n",
            "Epoch 31/100\n",
            "5804/5804 [==============================] - 117s 20ms/step - loss: 0.6571\n",
            "Epoch 32/100\n",
            "5804/5804 [==============================] - 117s 20ms/step - loss: 0.4938\n",
            "Epoch 33/100\n",
            "5804/5804 [==============================] - 117s 20ms/step - loss: 0.3881\n",
            "Epoch 34/100\n",
            "5804/5804 [==============================] - 117s 20ms/step - loss: 0.2856\n",
            "Epoch 35/100\n",
            "5804/5804 [==============================] - 117s 20ms/step - loss: 0.2155\n",
            "Epoch 36/100\n",
            "5804/5804 [==============================] - 117s 20ms/step - loss: 0.1449\n",
            "Epoch 37/100\n",
            "5804/5804 [==============================] - 117s 20ms/step - loss: 0.1008\n",
            "Epoch 38/100\n",
            "5804/5804 [==============================] - 117s 20ms/step - loss: 0.0733\n",
            "Epoch 39/100\n",
            "5804/5804 [==============================] - 117s 20ms/step - loss: 0.0598\n",
            "Epoch 40/100\n",
            "5804/5804 [==============================] - 118s 20ms/step - loss: 0.0466\n",
            "Epoch 41/100\n",
            "5804/5804 [==============================] - 118s 20ms/step - loss: 0.0374\n",
            "Epoch 42/100\n",
            "5804/5804 [==============================] - 117s 20ms/step - loss: 0.0336\n",
            "Epoch 43/100\n",
            "5804/5804 [==============================] - 118s 20ms/step - loss: 0.0497\n",
            "Epoch 44/100\n",
            "5804/5804 [==============================] - 118s 20ms/step - loss: 0.0559\n",
            "Epoch 45/100\n",
            "5804/5804 [==============================] - 118s 20ms/step - loss: 0.0341\n",
            "Epoch 46/100\n",
            "5804/5804 [==============================] - 117s 20ms/step - loss: 0.0213\n",
            "Epoch 47/100\n",
            "5804/5804 [==============================] - 117s 20ms/step - loss: 0.0870\n",
            "Epoch 48/100\n",
            "5804/5804 [==============================] - 117s 20ms/step - loss: 0.0536\n",
            "Epoch 49/100\n",
            "5804/5804 [==============================] - 117s 20ms/step - loss: 0.0451\n",
            "Epoch 50/100\n",
            "5804/5804 [==============================] - 117s 20ms/step - loss: 0.0245\n",
            "Epoch 51/100\n",
            "5804/5804 [==============================] - 117s 20ms/step - loss: 0.0123\n",
            "Epoch 52/100\n",
            "5804/5804 [==============================] - 117s 20ms/step - loss: 0.0087\n",
            "Epoch 53/100\n",
            "5804/5804 [==============================] - 117s 20ms/step - loss: 0.0062\n",
            "Epoch 54/100\n",
            "5804/5804 [==============================] - 117s 20ms/step - loss: 0.0053\n",
            "Epoch 55/100\n",
            "5804/5804 [==============================] - 117s 20ms/step - loss: 0.0066\n",
            "Epoch 56/100\n",
            "5804/5804 [==============================] - 117s 20ms/step - loss: 0.0041\n",
            "Epoch 57/100\n",
            "5804/5804 [==============================] - 117s 20ms/step - loss: 0.0038\n",
            "Epoch 58/100\n",
            "5804/5804 [==============================] - 117s 20ms/step - loss: 0.0031\n",
            "Epoch 59/100\n",
            "5804/5804 [==============================] - 117s 20ms/step - loss: 0.0029\n",
            "Epoch 60/100\n",
            "5804/5804 [==============================] - 116s 20ms/step - loss: 0.0127\n",
            "Epoch 61/100\n",
            "5804/5804 [==============================] - 117s 20ms/step - loss: 0.3102\n",
            "Epoch 62/100\n",
            "5804/5804 [==============================] - 117s 20ms/step - loss: 0.3220\n",
            "Epoch 63/100\n",
            "5804/5804 [==============================] - 117s 20ms/step - loss: 0.1006\n",
            "Epoch 64/100\n",
            "5804/5804 [==============================] - 117s 20ms/step - loss: 0.0398\n",
            "Epoch 65/100\n",
            "5804/5804 [==============================] - 117s 20ms/step - loss: 0.0181\n",
            "Epoch 66/100\n",
            "5804/5804 [==============================] - 116s 20ms/step - loss: 0.0107\n",
            "Epoch 67/100\n",
            "5804/5804 [==============================] - 117s 20ms/step - loss: 0.0084\n",
            "Epoch 68/100\n",
            "5804/5804 [==============================] - 117s 20ms/step - loss: 0.0067\n",
            "Epoch 69/100\n",
            "5804/5804 [==============================] - 116s 20ms/step - loss: 0.0059\n",
            "Epoch 70/100\n",
            "5804/5804 [==============================] - 117s 20ms/step - loss: 0.0058\n",
            "Epoch 71/100\n",
            "5804/5804 [==============================] - 117s 20ms/step - loss: 0.0057\n",
            "Epoch 72/100\n",
            "5804/5804 [==============================] - 117s 20ms/step - loss: 0.0046\n",
            "Epoch 73/100\n",
            "5804/5804 [==============================] - 117s 20ms/step - loss: 0.0037\n",
            "Epoch 74/100\n",
            "5804/5804 [==============================] - 117s 20ms/step - loss: 0.0036\n",
            "Epoch 75/100\n",
            "5804/5804 [==============================] - 117s 20ms/step - loss: 0.0032\n",
            "Epoch 76/100\n",
            "5804/5804 [==============================] - 117s 20ms/step - loss: 0.0025\n",
            "Epoch 77/100\n",
            "5804/5804 [==============================] - 117s 20ms/step - loss: 0.0026\n",
            "Epoch 78/100\n",
            "5804/5804 [==============================] - 117s 20ms/step - loss: 0.0022\n",
            "Epoch 79/100\n",
            "5804/5804 [==============================] - 117s 20ms/step - loss: 0.0020\n",
            "Epoch 80/100\n",
            "5804/5804 [==============================] - 117s 20ms/step - loss: 0.0019\n",
            "Epoch 81/100\n",
            "5804/5804 [==============================] - 117s 20ms/step - loss: 0.0088\n",
            "Epoch 82/100\n",
            "5804/5804 [==============================] - 117s 20ms/step - loss: 0.0806\n",
            "Epoch 83/100\n",
            "5804/5804 [==============================] - 117s 20ms/step - loss: 0.3208\n",
            "Epoch 84/100\n",
            "5804/5804 [==============================] - 117s 20ms/step - loss: 0.1541\n",
            "Epoch 85/100\n",
            "5804/5804 [==============================] - 117s 20ms/step - loss: 0.0516\n",
            "Epoch 86/100\n",
            "5804/5804 [==============================] - 117s 20ms/step - loss: 0.0222\n",
            "Epoch 87/100\n",
            "5804/5804 [==============================] - 117s 20ms/step - loss: 0.0111\n",
            "Epoch 88/100\n",
            "5804/5804 [==============================] - 117s 20ms/step - loss: 0.0084\n",
            "Epoch 89/100\n",
            "5804/5804 [==============================] - 118s 20ms/step - loss: 0.0067\n",
            "Epoch 90/100\n",
            "5804/5804 [==============================] - 117s 20ms/step - loss: 0.0046\n",
            "Epoch 91/100\n",
            "5804/5804 [==============================] - 117s 20ms/step - loss: 0.0035\n",
            "Epoch 92/100\n",
            "5804/5804 [==============================] - 117s 20ms/step - loss: 0.0034\n",
            "Epoch 93/100\n",
            "5804/5804 [==============================] - 117s 20ms/step - loss: 0.0029\n",
            "Epoch 94/100\n",
            "5804/5804 [==============================] - 117s 20ms/step - loss: 0.0021\n",
            "Epoch 95/100\n",
            "5804/5804 [==============================] - 117s 20ms/step - loss: 0.0022\n",
            "Epoch 96/100\n",
            "5804/5804 [==============================] - 117s 20ms/step - loss: 0.0017\n",
            "Epoch 97/100\n",
            "5804/5804 [==============================] - 117s 20ms/step - loss: 0.0019\n",
            "Epoch 98/100\n",
            "5804/5804 [==============================] - 117s 20ms/step - loss: 0.0019\n",
            "Epoch 99/100\n",
            "5804/5804 [==============================] - 117s 20ms/step - loss: 0.0015\n",
            "Epoch 100/100\n",
            "5804/5804 [==============================] - 117s 20ms/step - loss: 0.0014\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f446caab8d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zz6z2vyN7pVi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "string_mapped = x[20]\n",
        "full_string = [n_to_char[value] for value in string_mapped]\n",
        "# generating characters\n",
        "for i in range(500):\n",
        "    x = np.reshape(string_mapped,(1,len(string_mapped), 1))\n",
        "    x = x / float(len(characters))\n",
        "\n",
        "    pred_index = np.argmax(model.predict(x, verbose=0))\n",
        "    seq = [n_to_char[value] for value in string_mapped]\n",
        "    full_string.append(n_to_char[pred_index])\n",
        "\n",
        "    string_mapped.append(pred_index)\n",
        "    \n",
        "    string_mapped = string_mapped[1:len(string_mapped)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWCILjrS7vr4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "f2281a61-1a7c-4729-9deb-e6b1ac234aab"
      },
      "source": [
        "txt=\"\"\n",
        "for char in full_string:\n",
        "    txt = txt+char\n",
        "txt"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ess diana stood at the entrance to the bar, dazzled by the flash of cameras. a few drinkers turned in her direction as she entered, and one or two waved. she paused in front of the floor light so that it shone through her diaphanous dress for a moment, then headed for the bar.\\n\\n“hi, micky.”\\n\\nmichael jackson swivelled on his bar stool and grinned a welcome.\\n\\n“well good evening,” he said, beaming, leaving a small gap before adding “your highness”.\\n\\nprincess diana blushed, dipped her head and looked up at him through artfully sculpted lashes.\\n\\n“oh, you,” she muttered playfully, but glad that he’d'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJkCJukABe0y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "c1be27a1-7967-46ce-ce90-47f9cb5162af"
      },
      "source": [
        "print(txt)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ess diana stood at the entrance to the bar, dazzled by the flash of cameras. a few drinkers turned in her direction as she entered, and one or two waved. she paused in front of the floor light so that it shone through her diaphanous dress for a moment, then headed for the bar.\n",
            "\n",
            "“hi, micky.”\n",
            "\n",
            "michael jackson swivelled on his bar stool and grinned a welcome.\n",
            "\n",
            "“well good evening,” he said, beaming, leaving a small gap before adding “your highness”.\n",
            "\n",
            "princess diana blushed, dipped her head and looked up at him through artfully sculpted lashes.\n",
            "\n",
            "“oh, you,” she muttered playfully, but glad that he’d\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmcwqHclS02L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}